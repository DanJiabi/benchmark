#!/usr/bin/env python3
"""
ä¸‹è½½ config.yaml ä¸­é…ç½®çš„æ¨¡å‹æƒé‡æ–‡ä»¶
"""

import argparse
import hashlib
import sys
from pathlib import Path
from typing import Dict, Any
import yaml
import requests


def get_file_hash(file_path: Path, algorithm: str = "md5") -> str:
    """è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
    hash_func = getattr(hashlib, algorithm)()
    chunk_size = 8192
    with open(file_path, "rb") as f:
        while chunk := f.read(chunk_size):
            hash_func.update(chunk)
    return hash_func.hexdigest()


def get_expected_hash(url: str) -> str:
    """ä» GitHub è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
    try:
        # GitHub API è·å–æ–‡ä»¶ä¿¡æ¯
        if "github.com" in url:
            api_url = url.replace(
                "https://github.com/", "https://api.github.com/repos/"
            ).replace("/releases/download/", "/releases/assets/")

            # å°è¯•è·å–æ–‡ä»¶åˆ—è¡¨
            headers = {"Accept": "application/vnd.github.v3+json"}
            response = requests.get(api_url, headers=headers, timeout=10)
            if response.status_code == 200:
                # è¿”å› Noneï¼Œå› ä¸ºæˆ‘ä»¬æ— æ³•ç›´æ¥è·å–å“ˆå¸Œ
                return None

        return None
    except Exception:
        return None


def get_min_expected_size(file_name: str) -> int:
    """æ ¹æ®æ–‡ä»¶åè·å–æœ€å°é¢„æœŸå¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
    file_name = file_name.lower()

    # YOLO æ¨¡å‹æ–‡ä»¶å¤§å°å‚è€ƒ
    if "yolov8n" in file_name:
        return 5 * 1024 * 1024  # 5 MB
    elif "yolov8s" in file_name:
        return 10 * 1024 * 1024  # 10 MB
    elif "yolov8m" in file_name:
        return 20 * 1024 * 1024  # 20 MB
    elif "yolov8l" in file_name:
        return 40 * 1024 * 1024  # 40 MB
    elif "yolov8x" in file_name:
        return 60 * 1024 * 1024  # 60 MB
    elif "yolov9t" in file_name:
        return 5 * 1024 * 1024  # 5 MB
    elif "yolov9s" in file_name:
        return 10 * 1024 * 1024  # 10 MB
    elif "yolov9m" in file_name:
        return 20 * 1024 * 1024  # 20 MB
    elif "yolov10n" in file_name:
        return 5 * 1024 * 1024  # 5 MB
    elif "yolov10s" in file_name:
        return 10 * 1024 * 1024  # 10 MB
    elif "yolov10m" in file_name:
        return 20 * 1024 * 1024  # 20 MB
    elif "yolov10b" in file_name:
        return 30 * 1024 * 1024  # 30 MB
    elif "rtdetr-l" in file_name:
        return 50 * 1024 * 1024  # 50 MB
    elif "rtdetr-x" in file_name:
        return 100 * 1024 * 1024  # 100 MB

    # é»˜è®¤æœ€å°å¤§å°ï¼šè‡³å°‘ 100KB
    return 100 * 1024


def check_file_complete(file_path: Path, expected_size: int = None) -> tuple[bool, str]:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´"""
    if not file_path.exists():
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"

    file_size = file_path.stat().st_size

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if file_size == 0:
        return False, "æ–‡ä»¶ä¸ºç©º"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿‡å°ï¼ˆä¸å®Œæ•´ï¼‰
    min_size = get_min_expected_size(file_path.name)
    if file_size < min_size:
        size_mb = file_size / 1024 / 1024
        min_mb = min_size / 1024 / 1024
        return False, f"æ–‡ä»¶è¿‡å° ({size_mb:.2f} MB < {min_mb:.2f} MB), å¯èƒ½ä¸‹è½½ä¸å®Œæ•´"

    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åŒ¹é…é¢„æœŸ
    if expected_size and file_size < expected_size * 0.95:
        return False, f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {file_size} < {expected_size}"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯ä»¥è¯»å–
    try:
        with open(file_path, "rb") as f:
            data = f.read(1024)
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶ï¼ˆPyTorch checkpoint æˆ–å…¶ä»–æ ¼å¼ï¼‰
            if len(data) < 10:
                return False, "æ–‡ä»¶å†…å®¹å¼‚å¸¸"
    except Exception as e:
        return False, f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}"

    # å°è¯•åŠ è½½éªŒè¯ï¼ˆå¯é€‰ï¼Œéœ€è¦å®‰è£… torchï¼‰
    try:
        import torch

        try:
            # å°è¯•åŠ è½½æ–‡ä»¶ï¼ˆä»…åŠ è½½æƒé‡ï¼‰
            checkpoint = torch.load(file_path, map_location="cpu", weights_only=True)
            # æ£€æŸ¥åŠ è½½çš„å†…å®¹æ˜¯å¦åˆç†
            if isinstance(checkpoint, dict):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¸å‹çš„ PyTorch checkpoint é”®
                valid_keys = ["model", "state_dict", "ema", "model_state_dict"]
                has_valid_key = any(key in checkpoint for key in valid_keys)
                if has_valid_key or len(checkpoint) > 0:
                    return True, "æ–‡ä»¶å®Œæ•´ä¸”å¯åŠ è½½"
            # å¯¹äº ULPALYCS æ ¼å¼çš„æ¨¡å‹
            elif hasattr(checkpoint, "model"):
                return True, "æ–‡ä»¶å®Œæ•´ä¸”å¯åŠ è½½"
        except Exception as load_error:
            error_str = str(load_error)
            # è¿‡æ»¤æ‰ PyTorch 2.6 çš„è­¦å‘Šä¿¡æ¯
            if "Weights only load failed" in error_str:
                try:
                    # å°è¯•ä½¿ç”¨ weights_only=False
                    checkpoint = torch.load(
                        file_path, map_location="cpu", weights_only=False
                    )
                    return True, "æ–‡ä»¶å®Œæ•´ä¸”å¯åŠ è½½"
                except Exception:
                    return False, "æ–‡ä»¶åŠ è½½å¤±è´¥"
            else:
                # å…¶ä»–åŠ è½½é”™è¯¯
                return False, f"æ–‡ä»¶åŠ è½½å¤±è´¥: {load_error}"
    except ImportError:
        # æœªå®‰è£… torchï¼Œè·³è¿‡åŠ è½½éªŒè¯
        pass

    return True, "æ–‡ä»¶å®Œæ•´"


def download_file(
    url: str,
    output_path: Path,
    expected_size: int = None,
    overwrite: bool = False,
) -> bool:
    """ä¸‹è½½æ–‡ä»¶"""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”å®Œæ•´
    if not overwrite and output_path.exists():
        is_complete, message = check_file_complete(output_path, expected_size)
        if is_complete:
            print(f"  âœ… æ–‡ä»¶å·²å­˜åœ¨ä¸”å®Œæ•´: {output_path.name}")
            return True
        else:
            print(f"  âš ï¸  æ–‡ä»¶ä¸å®Œæ•´ ({message}), å°†é‡æ–°ä¸‹è½½")

    print(f"  ğŸ“¥ ä¸‹è½½: {url}")
    print(f"  ğŸ“ ä¿å­˜åˆ°: {output_path}")

    try:
        response = requests.get(url, stream=True, timeout=300)
        response.raise_for_status()

        total_size = int(response.headers.get("content-length", 0))
        downloaded_size = 0

        with open(output_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)

                    # æ˜¾ç¤ºè¿›åº¦
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        print(
                            f"\r  â³ è¿›åº¦: {progress:.1f}% ({downloaded_size}/{total_size})",
                            end="",
                        )

        print()  # æ¢è¡Œ

        # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
        if total_size > 0 and downloaded_size != total_size:
            print(f"  âš ï¸  ä¸‹è½½å¤§å°ä¸åŒ¹é…: {downloaded_size}/{total_size}")
            output_path.unlink()
            return False

        print(
            f"  âœ… ä¸‹è½½å®Œæˆ: {output_path.name} ({downloaded_size / 1024 / 1024:.2f} MB)"
        )
        return True

    except Exception as e:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {e}")
        if output_path.exists():
            output_path.unlink()
        return False


def load_config(config_path: str = "config.yaml") -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_file = Path(__file__).parent / config_path

    if not config_file.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        sys.exit(1)

    with open(config_file, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    return config


def download_models(
    config_path: str,
    models_cache: str = "models_cache",
    overwrite: bool = False,
) -> None:
    """ä¸‹è½½é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ¨¡å‹æƒé‡"""
    print("=" * 80)
    print("æ¨¡å‹æƒé‡ä¸‹è½½å·¥å…·")
    print("=" * 80)

    config = load_config(config_path)

    if "models" not in config:
        print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'models' èŠ‚")
        sys.exit(1)

    models = config["models"]
    cache_dir = Path(models_cache)
    cache_dir.mkdir(parents=True, exist_ok=True)

    print(f"\né…ç½®æ–‡ä»¶: {config_path}")
    print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"æ¨¡å‹æ•°é‡: {len(models)}")
    print("=" * 80)

    success_count = 0
    fail_count = 0
    skip_count = 0
    incomplete_count = 0

    results = []

    for idx, model_config in enumerate(models, 1):
        print(f"\n[{idx}/{len(models)}] å¤„ç†æ¨¡å‹")
        print("-" * 80)

        model_name = model_config.get("name", "unknown")
        weights = model_config.get("weights")
        url = model_config.get("url")

        if weights is None:
            print(f"  â„¹ï¸  {model_name}: æ— æƒé‡æ–‡ä»¶ï¼ˆå¯èƒ½ä½¿ç”¨å†…ç½®é¢„è®­ç»ƒæƒé‡ï¼‰")
            skip_count += 1
            results.append((model_name, "skip", "æ— æƒé‡æ–‡ä»¶"))
            continue

        if not url:
            print(f"  âš ï¸  {model_name}: æœªæä¾›ä¸‹è½½ URL")
            fail_count += 1
            results.append((model_name, "fail", "æœªæä¾› URL"))
            continue

        weights_path = cache_dir / weights

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦éœ€è¦ä¸‹è½½
        need_download = overwrite

        if not overwrite and weights_path.exists():
            is_complete, message = check_file_complete(weights_path)
            if not is_complete:
                print(f"  âš ï¸  {message}")
                need_download = True
                incomplete_count += 1
        else:
            if not overwrite:
                print(f"  ğŸ” æ–‡ä»¶ä¸å­˜åœ¨: {weights}")
                need_download = True
                incomplete_count += 1

        # ä¸‹è½½æ–‡ä»¶
        if need_download:
            success = download_file(url, weights_path)
            if success:
                success_count += 1
                results.append((model_name, "download", "ä¸‹è½½æˆåŠŸ"))
            else:
                fail_count += 1
                results.append((model_name, "fail", "ä¸‹è½½å¤±è´¥"))
        else:
            skip_count += 1
            results.append((model_name, "skip", "æ–‡ä»¶å·²å­˜åœ¨ä¸”å®Œæ•´"))

    # æ‰“å°æ±‡æ€»
    print("\n" + "=" * 80)
    print("ä¸‹è½½æ±‡æ€»")
    print("=" * 80)
    print(f"  æ€»æ¨¡å‹æ•°: {len(models)}")
    print(f"  ä¸‹è½½æˆåŠŸ: {success_count}")
    print(f"  é‡æ–°ä¸‹è½½ï¼ˆä¸å®Œæ•´ï¼‰: {incomplete_count}")
    print(f"  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {skip_count}")
    print(f"  ä¸‹è½½å¤±è´¥: {fail_count}")
    print("=" * 80)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    results_file = cache_dir / "download_results.txt"
    with open(results_file, "w", encoding="utf-8") as f:
        f.write("æ¨¡å‹æƒé‡ä¸‹è½½ç»“æœ\n")
        f.write("=" * 80 + "\n\n")
        for model_name, status, message in results:
            f.write(f"{model_name}: {status} - {message}\n")

    print(f"ç»“æœå·²ä¿å­˜: {results_file}")


def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½ config.yaml ä¸­çš„æ¨¡å‹æƒé‡æ–‡ä»¶")
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.yamlï¼‰",
    )
    parser.add_argument(
        "--cache-dir",
        type=str,
        default="models_cache",
        help="ç¼“å­˜ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: models_cacheï¼‰",
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶",
    )
    parser.add_argument(
        "--check-only",
        action="store_true",
        help="ä»…æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§ï¼Œä¸ä¸‹è½½",
    )

    args = parser.parse_args()

    if args.check_only:
        # ä»…æ£€æŸ¥æ¨¡å¼
        print("=" * 80)
        print("æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶å®Œæ•´æ€§")
        print("=" * 80)

        config = load_config(args.config)
        cache_dir = Path(args.cache_dir)

        if "models" not in config:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'models' èŠ‚")
            sys.exit(1)

        models = config["models"]

        for idx, model_config in enumerate(models, 1):
            model_name = model_config.get("name", "unknown")
            weights = model_config.get("weights")

            if weights is None:
                continue

            weights_path = cache_dir / weights

            if weights_path.exists():
                is_complete, message = check_file_complete(weights_path)
                status = "âœ… å®Œæ•´" if is_complete else "âŒ ä¸å®Œæ•´"
                print(
                    f"[{idx}/{len(models)}] {model_name:20s} {status:10s} - {message}"
                )
            else:
                print(f"[{idx}/{len(models)}] {model_name:20s} âš ï¸  ä¸å­˜åœ¨")
    else:
        # ä¸‹è½½æ¨¡å¼
        download_models(args.config, args.cache_dir, args.overwrite)


if __name__ == "__main__":
    main()
